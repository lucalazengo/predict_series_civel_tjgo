{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c797f7cd",
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Data Preparation Script for TJGO Forecasting Project - TEST VERSION\n",
    "This version:\n",
    "- Excludes 2014 data (starts from 2015)\n",
    "- Removes high correlation variables (qt_acidente, QT_ELEITOR)\n",
    "- Uses only traditional economic variables\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c00312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Starting TEST data preparation...\")\n",
    "    print(\"ðŸ”¬ TEST CONFIGURATION:\")\n",
    "    print(\"  - Excluding 2014 data\")\n",
    "    print(\"  - Removing qt_acidente and QT_ELEITOR\")\n",
    "    print(\"  - Using only traditional economic variables\")\n",
    "    \n",
    "    # Load data\n",
    "    data_path = './data/raw/base_consolidada_mensal_clean.csv'\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['DATA'] = pd.to_datetime(df['DATA'])\n",
    "    df = df.set_index('DATA').sort_index()\n",
    "    \n",
    "    print(\"\\nData loaded: \" + str(df.shape[0]) + \" observations, \" + str(df.shape[1]) + \" variables\")\n",
    "    print(\"Period: \" + df.index.min().strftime('%Y-%m') + \" to \" + df.index.max().strftime('%Y-%m'))\n",
    "    # Remove 2014 data (start from 2015)\n",
    "    df = df[df.index >= '2015-01-01']\n",
    "    print(\"After removing 2014: \" + str(len(df)) + \" observations\")\n",
    "    print(\"New period: \" + df.index.min().strftime('%Y-%m') + \" to \" + df.index.max().strftime('%Y-%m'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove high correlation variables\n",
    "    variables_to_remove = ['qt_acidente', 'QT_ELEITOR']\n",
    "    df = df.drop(columns=variables_to_remove)\n",
    "    print(\"Removed variables: \" + str(variables_to_remove))\n",
    "    print(\"Remaining variables: \" + str(list(df.columns)))\n",
    "    \n",
    "    # Handle missing values\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    print(\"Missing values handled: \" + str(df.isnull().sum().sum()) + \" remaining\")\n",
    "    \n",
    "    # Create time features\n",
    "    df['year'] = df.index.year\n",
    "    df['month'] = df.index.month\n",
    "    df['quarter'] = df.index.quarter\n",
    "    \n",
    "    # Create lag features\n",
    "    for lag in [1, 2, 3, 6, 12]:\n",
    "        df['TOTAL_CASOS_lag_' + str(lag)] = df['TOTAL_CASOS'].shift(lag)\n",
    "    \n",
    "    # Create rolling features\n",
    "    for window in [3, 6, 12]:\n",
    "        df['TOTAL_CASOS_rolling_mean_' + str(window)] = df['TOTAL_CASOS'].rolling(window=window).mean()\n",
    "        df['TOTAL_CASOS_rolling_std_' + str(window)] = df['TOTAL_CASOS'].rolling(window=window).std()\n",
    "    \n",
    "    # Handle missing values more carefully to preserve more data\n",
    "    # Fill forward for lag features (use last known value)\n",
    "    for lag in [1, 2, 3, 6, 12]:\n",
    "        df['TOTAL_CASOS_lag_' + str(lag)] = df['TOTAL_CASOS_lag_' + str(lag)].fillna(method='ffill')\n",
    "    \n",
    "    # Fill forward for rolling statistics\n",
    "    for window in [3, 6, 12]:\n",
    "        df['TOTAL_CASOS_rolling_mean_' + str(window)] = df['TOTAL_CASOS_rolling_mean_' + str(window)].fillna(method='ffill')\n",
    "        df['TOTAL_CASOS_rolling_std_' + str(window)] = df['TOTAL_CASOS_rolling_std_' + str(window)].fillna(method='ffill')\n",
    "    \n",
    "    # Handle any remaining missing values\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # Only remove rows that still have NaN (should be minimal now)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Split data temporally\n",
    "    n_total = len(df)\n",
    "    n_test = int(n_total * 0.2)\n",
    "    n_train = n_total - n_test\n",
    "    \n",
    "    train_data = df.iloc[:n_train].copy()\n",
    "    test_data = df.iloc[n_train:].copy()\n",
    "    \n",
    "    print(\"\\nTrain data: \" + str(len(train_data)) + \" observations (\" + train_data.index.min().strftime('%Y-%m') + \" to \" + train_data.index.max().strftime('%Y-%m') + \")\")\n",
    "    print(\"Test data: \" + str(len(test_data)) + \" observations (\" + test_data.index.min().strftime('%Y-%m') + \" to \" + test_data.index.max().strftime('%Y-%m') + \")\")\n",
    "    \n",
    "    # Create output directory for test data\n",
    "    os.makedirs('./data/processed_test/', exist_ok=True)\n",
    "    \n",
    "    # Save processed data with TEST suffix\n",
    "    df.to_csv('./data/processed_test/data_processed_test.csv')\n",
    "    train_data.to_csv('./data/processed_test/train_test.csv')\n",
    "    test_data.to_csv('./data/processed_test/test_test.csv')\n",
    "    \n",
    "    print(\"\\nâœ… TEST data preparation completed successfully!\")\n",
    "    print(\"Total features created: \" + str(len(df.columns)))\n",
    "    print(\"Files saved in: ./data/processed_test/\")\n",
    "    \n",
    "    return df, train_data, test_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, train_data, test_data = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tjgo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
