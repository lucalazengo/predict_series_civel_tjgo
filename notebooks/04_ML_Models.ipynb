{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“Š Notebook: Modelos de Machine Learning - Forecasting TJGO\n",
        "\n",
        "Este notebook demonstra o uso de modelos de machine learning para previsÃ£o de casos no TJGO:\n",
        "- Random Forest\n",
        "- XGBoost  \n",
        "- LightGBM\n",
        "- Modelos Baseline\n",
        "\n",
        "## ðŸŽ¯ Objetivos\n",
        "- Treinar modelos de ML com features temporais\n",
        "- Analisar importÃ¢ncia das features\n",
        "- Comparar performance entre modelos\n",
        "- Avaliar resÃ­duos e diagnÃ³sticos\n",
        "\n",
        "## ðŸ“ˆ CaracterÃ­sticas dos Modelos ML\n",
        "- **Random Forest**: Ensemble de Ã¡rvores, robusto a overfitting\n",
        "- **XGBoost**: Gradient boosting otimizado, alta performance\n",
        "- **LightGBM**: Gradient boosting eficiente, rÃ¡pido treinamento\n",
        "- **Features**: Lags, rolling statistics, variÃ¡veis exÃ³genas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ImportaÃ§Ãµes necessÃ¡rias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Importar modelos de ML\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from models.ml_models import (\n",
        "    RandomForestModel, XGBoostModel, LightGBMModel, BaselineModels,\n",
        "    train_random_forest_model, train_xgboost_model, train_lightgbm_model,\n",
        "    train_baseline_models\n",
        ")\n",
        "\n",
        "# Configurar matplotlib\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"âœ… Bibliotecas importadas com sucesso!\")\n",
        "print(\"ðŸ“Š Pronto para usar os modelos de ML\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar dados processados\n",
        "train_data = pd.read_csv('../data/processed_test/train_test.csv', index_col='DATA', parse_dates=True)\n",
        "test_data = pd.read_csv('../data/processed_test/test_test.csv', index_col='DATA', parse_dates=True)\n",
        "\n",
        "print(\"ðŸ“Š Dados carregados:\")\n",
        "print(f\"  Treino: {len(train_data)} observaÃ§Ãµes\")\n",
        "print(f\"  Teste:  {len(test_data)} observaÃ§Ãµes\")\n",
        "print(f\"  VariÃ¡veis: {len(train_data.columns)}\")\n",
        "\n",
        "# Visualizar features disponÃ­veis\n",
        "print(\"\\nðŸ“‹ Features disponÃ­veis:\")\n",
        "feature_cols = train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "for i, col in enumerate(feature_cols):\n",
        "    print(f\"  {i+1:2d}. {col}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ 2. Treinamento dos Modelos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treinar modelos baseline\n",
        "print(\"ðŸ”„ Treinando modelos baseline...\")\n",
        "baseline_models = train_baseline_models(train_data, test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treinar Random Forest\n",
        "print(\"\\nðŸ”„ Treinando Random Forest...\")\n",
        "rf_model = train_random_forest_model(train_data, test_data)\n",
        "rf_model.print_summary(\"Random Forest\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treinar XGBoost\n",
        "print(\"\\nðŸ”„ Treinando XGBoost...\")\n",
        "xgb_model = train_xgboost_model(train_data, test_data)\n",
        "xgb_model.print_summary(\"XGBoost\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treinar LightGBM\n",
        "print(\"\\nðŸ”„ Treinando LightGBM...\")\n",
        "lgb_model = train_lightgbm_model(train_data, test_data)\n",
        "lgb_model.print_summary(\"LightGBM\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ˆ 3. AnÃ¡lises e VisualizaÃ§Ãµes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotar previsÃµes de todos os modelos\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "models = [\n",
        "    (baseline_models.baseline_results['persistence'], 'Baseline PersistÃªncia'),\n",
        "    (baseline_models.baseline_results['moving_average'], 'Baseline MÃ©dia MÃ³vel'),\n",
        "    (rf_model, 'Random Forest'),\n",
        "    (xgb_model, 'XGBoost')\n",
        "]\n",
        "\n",
        "for i, (model_data, name) in enumerate(models):\n",
        "    ax = axes[i]\n",
        "    \n",
        "    if isinstance(model_data, dict):\n",
        "        predictions = model_data['predictions']\n",
        "        metrics = model_data['metrics']\n",
        "        mae = metrics['mae']\n",
        "    else:\n",
        "        predictions = model_data.predictions\n",
        "        mae = model_data.metrics['mae']\n",
        "    \n",
        "    # Plotar dados reais e previsÃµes\n",
        "    ax.plot(test_data.index, test_data['TOTAL_CASOS'], \n",
        "           label='Real', linewidth=2, color='blue')\n",
        "    ax.plot(test_data.index, predictions, \n",
        "           label='PrevisÃ£o', linewidth=2, color='red', linestyle='--')\n",
        "    \n",
        "    ax.set_title(f\"{name} (MAE: {mae:.0f})\", fontweight='bold')\n",
        "    ax.set_xlabel('Data')\n",
        "    ax.set_ylabel('TOTAL_CASOS')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../reports_test/ml_models_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analisar importÃ¢ncia das features (Random Forest)\n",
        "rf_model.plot_feature_importance(\"Random Forest\", top_n=10, \n",
        "                                save_path=\"../reports_test/rf_feature_importance.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analisar importÃ¢ncia das features (XGBoost)\n",
        "xgb_model.plot_feature_importance(\"XGBoost\", top_n=10, \n",
        "                                  save_path=\"../reports_test/xgb_feature_importance.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotar resÃ­duos dos modelos\n",
        "rf_model.plot_residuals(\"Random Forest\", save_path=\"../reports_test/rf_residuals.png\")\n",
        "xgb_model.plot_residuals(\"XGBoost\", save_path=\"../reports_test/xgb_residuals.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
